{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SISTEM IDENTIFIKASI SENTIMEN DATA TEKS MENGGUNAKAN METODE SUPPORT VECTOR MACHINE (SVM)\n",
        "\n",
        "Yan Pieter Israel Rumere\t\t(1808561082)\n",
        "\n",
        "Ratri Desy Christirahma\t\t(2108561003)\n",
        "\n",
        "Saifulloh Rahman\t\t\t(2108561028)\n",
        "\n",
        "Nyoman Krisna Ari Sudarsana\t( 2108561072)\n"
      ],
      "metadata": {
        "id": "sYwpvgFitFkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Google Drive"
      ],
      "metadata": {
        "id": "HafSvsHmNOvM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEA1dqKxNlsK",
        "outputId": "ea70232e-9850-4884-d0eb-e7972aaebd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab-Notebooks/final-project\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab-Notebooks/final-project/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library"
      ],
      "metadata": {
        "id": "3hShbMg_NTOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Library untuk SVM\n",
        "from flask import Flask, render_template, url_for\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Packages untuk visuals\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(font_scale=1.2)\n",
        "\n",
        "# Library/packages untuk preprocessing\n",
        "import re\n",
        "!pip install Sastrawi\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ],
      "metadata": {
        "id": "eOcb6MX1QOUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902b6fd1-fd21-4b3b-eb58-7259ae83101c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m \u001b[32m204.8/209.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "TOXwRi4wNXJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset dari gdrive\n",
        "reviews = pd.read_csv(\"reviews.csv\")\n",
        "\n",
        "# menampilkan data\n",
        "reviews"
      ],
      "metadata": {
        "id": "kUk0sVWrQPQ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "61ce994a-e2ba-4ea3-87b4-90366081344b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      No                                            Reviews  Label\n",
              "0      1  kemeja nya bagusss bgttttüòçüòçüòçaaaa mauuu nngisss...      1\n",
              "1      2  Jahitannya sih rapi,cuman ada benang yang ikut...      0\n",
              "2      3  Sesuai harga. Agak tipis tapi masih oke kok. W...      0\n",
              "3      4  Wah gila sihhh sebagus itu, se worth it, se  l...      1\n",
              "4      5  Kain nya bagus halus  \\nTapi kok di bukak koto...      0\n",
              "..   ...                                                ...    ...\n",
              "826  827  Terima kasih barang sudah sampai sesuai ukuran...      1\n",
              "827  828  Mantapp realpicttt bangttt tapi pengemasan nya...      1\n",
              "828  829  Suka bgt sama tasnya, ga kayak tas local. Kere...      1\n",
              "829  830  kualitas produk sangat baik. produk original. ...      1\n",
              "830  831  Barang udah sampai dg selamat, mantul banget d...      1\n",
              "\n",
              "[831 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20d5317e-9b4c-4407-906a-9a10a52fba63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>kemeja nya bagusss bgttttüòçüòçüòçaaaa mauuu nngisss...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jahitannya sih rapi,cuman ada benang yang ikut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Sesuai harga. Agak tipis tapi masih oke kok. W...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Wah gila sihhh sebagus itu, se worth it, se  l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Kain nya bagus halus  \\nTapi kok di bukak koto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>827</td>\n",
              "      <td>Terima kasih barang sudah sampai sesuai ukuran...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>828</td>\n",
              "      <td>Mantapp realpicttt bangttt tapi pengemasan nya...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>829</td>\n",
              "      <td>Suka bgt sama tasnya, ga kayak tas local. Kere...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>830</td>\n",
              "      <td>kualitas produk sangat baik. produk original. ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>831</td>\n",
              "      <td>Barang udah sampai dg selamat, mantul banget d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20d5317e-9b4c-4407-906a-9a10a52fba63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20d5317e-9b4c-4407-906a-9a10a52fba63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20d5317e-9b4c-4407-906a-9a10a52fba63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "h0bSgB5aNbLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprpcessing\n",
        "# Membuat objek stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Membuat objek stopword remover\n",
        "factory = StopWordRemoverFactory()\n",
        "stopword = factory.create_stop_word_remover()\n",
        "\n",
        "# Lowercase\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: x.lower())\n",
        "\n",
        "# Removing new line (\\n)\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: x.replace('\\n', ''))\n",
        "\n",
        "# Removing Non-Alphabetic Characters\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: re.compile('[^a-zA-Z]').sub(\" \", x))\n",
        "\n",
        "# Tokenisasi\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: x.split())\n",
        "\n",
        "# Removing Last Character from Each Word:\n",
        "def removeAkhir(s):\n",
        "  cadangan = s[-1]\n",
        "  s = s.rstrip(s[-1])\n",
        "  return s + cadangan\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: [removeAkhir(i) for i in x])\n",
        "\n",
        "# Remove short word\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: [i for i in x if len(i) > 2])\n",
        "\n",
        "# Joining Tokens into a Sentence\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Stop word removal\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: stopword.remove(x))\n",
        "\n",
        "# Stemming\n",
        "reviews['Reviews'] = reviews['Reviews'].apply(lambda x: stemmer.stem(x))"
      ],
      "metadata": {
        "id": "WYsYgwUSuQuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reviews.to_csv(r\"/content/drive/MyDrive/Colab-Notebooks/final-project/preprocessed-data.csv\")"
      ],
      "metadata": {
        "id": "v1-Or1udArQq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data yg sudah di preprocessing\n",
        "reviews = pd.read_csv(\"preprocessed-data.csv\")"
      ],
      "metadata": {
        "id": "Xw7DihhBWrOP"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ujwXE47ix8-R",
        "outputId": "c285c5b7-4684-4fd2-a253-f907162e450f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0   No                                            Reviews  Label\n",
              "0             0    1  kemeja nya bagus bgt mau nngis knpa dri dlu be...      1\n",
              "1             1    2  jahit sih rapi cuman benang ikut jahit jadi jelek      0\n",
              "2             2    3  sesuai harga tipis masih oke kok warna abu kal...      0\n",
              "3             3    4  wah gila sih bagus worth lembut baju kirain ba...      1\n",
              "4             4    5   kain nya bagus halus kok bukak kotor warna putih      0\n",
              "..          ...  ...                                                ...    ...\n",
              "826         826  827  terima kasih barang sampai sesuai ukur seesuai...      1\n",
              "827         827  828  mantap realpict bangt emas nya cuman plastik a...      1\n",
              "828         828  829  suka bgt sama tas kayak tas local keren parah ...      1\n",
              "829         829  830  kualitas produk sangat baik produk original ha...      1\n",
              "830         830  831  barang udah selamat mantul banget dah baju ses...      1\n",
              "\n",
              "[831 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8546ddd-b5c8-453d-a449-4eda4a45d901\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>No</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>kemeja nya bagus bgt mau nngis knpa dri dlu be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>jahit sih rapi cuman benang ikut jahit jadi jelek</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>sesuai harga tipis masih oke kok warna abu kal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>wah gila sih bagus worth lembut baju kirain ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>kain nya bagus halus kok bukak kotor warna putih</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>826</th>\n",
              "      <td>826</td>\n",
              "      <td>827</td>\n",
              "      <td>terima kasih barang sampai sesuai ukur seesuai...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>827</td>\n",
              "      <td>828</td>\n",
              "      <td>mantap realpict bangt emas nya cuman plastik a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828</th>\n",
              "      <td>828</td>\n",
              "      <td>829</td>\n",
              "      <td>suka bgt sama tas kayak tas local keren parah ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>829</th>\n",
              "      <td>829</td>\n",
              "      <td>830</td>\n",
              "      <td>kualitas produk sangat baik produk original ha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>830</th>\n",
              "      <td>830</td>\n",
              "      <td>831</td>\n",
              "      <td>barang udah selamat mantul banget dah baju ses...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>831 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8546ddd-b5c8-453d-a449-4eda4a45d901')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8546ddd-b5c8-453d-a449-4eda4a45d901 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8546ddd-b5c8-453d-a449-4eda4a45d901');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data into training and test sets"
      ],
      "metadata": {
        "id": "PaL-PqynNe8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting 80% train & 20% test, random_state=42 --> konsisten\n",
        "train_X, test_X, train_Y, test_Y = model_selection.train_test_split(reviews['Reviews'], reviews['Label'], test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "tLmB-JYXSOAY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat data frame untuk set data train\n",
        "df_train80 = pd.DataFrame()\n",
        "df_train80['Reviews'] = train_X\n",
        "df_train80['Label'] = train_Y\n",
        "\n",
        "# membuat data frame untuk set data test\n",
        "df_test20 = pd.DataFrame()\n",
        "df_test20['Reviews'] = test_X\n",
        "df_test20['Label'] = test_Y"
      ],
      "metadata": {
        "id": "3gLptWHyT6T4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan data train\n",
        "df_train80"
      ],
      "metadata": {
        "id": "TKkdZKgiUHZv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "025629c1-1bba-455e-92ea-d97008cd95ea"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Reviews  Label\n",
              "477  gak pernah kecewa pokok nyaselalu bagus kirim ...      1\n",
              "346  jual teliti barang kirim aju dana sulit dana h...      0\n",
              "462                                        bagus cacat      1\n",
              "670  shoppe mal embel doang kualitas apa kek baju p...      0\n",
              "302  kirim nya lama banget terus udah smpei brng ny...      0\n",
              "..                                                 ...    ...\n",
              "71   baju yang robek fatal bgt sumpah kecewa parah ...      0\n",
              "106  plis inimah nyesel beli doang bahan adem pis n...      1\n",
              "270  knp malah kirimin rusak sikecewa deh beli bara...      0\n",
              "435  gak usah ragu beli tas disinikualitasnya buagu...      1\n",
              "102  bagus pol cuma emang model tangan nya jadi kay...      1\n",
              "\n",
              "[664 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29faa48e-0a19-410c-b29a-5694c48a562a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>gak pernah kecewa pokok nyaselalu bagus kirim ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>jual teliti barang kirim aju dana sulit dana h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>bagus cacat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>shoppe mal embel doang kualitas apa kek baju p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>kirim nya lama banget terus udah smpei brng ny...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>baju yang robek fatal bgt sumpah kecewa parah ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>plis inimah nyesel beli doang bahan adem pis n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>knp malah kirimin rusak sikecewa deh beli bara...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>gak usah ragu beli tas disinikualitasnya buagu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>bagus pol cuma emang model tangan nya jadi kay...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>664 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29faa48e-0a19-410c-b29a-5694c48a562a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29faa48e-0a19-410c-b29a-5694c48a562a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29faa48e-0a19-410c-b29a-5694c48a562a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan data test\n",
        "df_test20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "9pH5zwlQkAHH",
        "outputId": "67ddb8fa-96d9-4f68-c1c4-f7c791524c55"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Reviews  Label\n",
              "610  kecewa sih sen nya warna hitam pas dateng nya ...      0\n",
              "818  produk bagus sesuai sama gambar banget gitu ha...      1\n",
              "290   bagus cuman susah atur jam nya susah tekan tekan      0\n",
              "559     warna beda jauh digmbr jatuh nya wrnanya gelap      0\n",
              "168  bagus kacamata mewah kayak mahal banget tebel ...      1\n",
              "..                                                 ...    ...\n",
              "192                        bagus cuma kirim lama bagus      1\n",
              "650  kecewa ukur kaya ukur kecil bgt bahan tipis st...      0\n",
              "456  jual gak amanah pesan datang cuma responnya la...      0\n",
              "773                                              bagus      1\n",
              "531  kecewa sen sma cepol tpi dateng kerudung nya d...      0\n",
              "\n",
              "[167 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1b21597-0d70-4ad2-855e-0e1826e39369\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>kecewa sih sen nya warna hitam pas dateng nya ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>produk bagus sesuai sama gambar banget gitu ha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>bagus cuman susah atur jam nya susah tekan tekan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>warna beda jauh digmbr jatuh nya wrnanya gelap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>bagus kacamata mewah kayak mahal banget tebel ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>bagus cuma kirim lama bagus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>kecewa ukur kaya ukur kecil bgt bahan tipis st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>jual gak amanah pesan datang cuma responnya la...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>bagus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>kecewa sen sma cepol tpi dateng kerudung nya d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>167 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1b21597-0d70-4ad2-855e-0e1826e39369')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1b21597-0d70-4ad2-855e-0e1826e39369 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1b21597-0d70-4ad2-855e-0e1826e39369');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# menyimpan data train dan test\n",
        "#df_train80.to_csv('df_train80.csv')\n",
        "#df_test20.to_csv('df_test20.csv')"
      ],
      "metadata": {
        "id": "pID0sCs6Udd_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction\n",
        "TF-IDF"
      ],
      "metadata": {
        "id": "09zEglZINmbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Membuat objek vectorizer\n",
        "tfidf_vect_8020 = TfidfVectorizer()\n",
        "\n",
        "# Menghitung bobot TF-IDF\n",
        "tfidf_vect_8020.fit(reviews['Reviews'])\n",
        "\n",
        "# representasi vektor TF-IDF untuk data train & test\n",
        "train_X_tfidf_8020 = tfidf_vect_8020.transform(df_train80['Reviews'])\n",
        "test_X_tfidf_8020 = tfidf_vect_8020.transform(df_test20['Reviews'])"
      ],
      "metadata": {
        "id": "nj99aTorVMB_"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X_tfidf_8020)\n",
        "#print(test_X_tfidf_8020)\n",
        "# indeks kalimat, indeks kata/fitur, nilai tfidf"
      ],
      "metadata": {
        "id": "btu8SGjFaW0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c10a06fb-79c5-4ec2-f04a-bc0d09cce1b6"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 2043)\t0.3716004489097684\n",
            "  (0, 1919)\t0.3716004489097684\n",
            "  (0, 1725)\t0.20474007466736982\n",
            "  (0, 1519)\t0.22505780396306832\n",
            "  (0, 1466)\t0.22673585241912458\n",
            "  (0, 1427)\t0.1974020011620077\n",
            "  (0, 1360)\t0.3716004489097684\n",
            "  (0, 952)\t0.33496478767309334\n",
            "  (0, 938)\t0.12689327874717454\n",
            "  (0, 887)\t0.12689327874717454\n",
            "  (0, 709)\t0.2498994165728818\n",
            "  (0, 614)\t0.16699165471381475\n",
            "  (0, 424)\t0.17404933452822524\n",
            "  (0, 381)\t0.2321154837774788\n",
            "  (0, 176)\t0.22343139604535153\n",
            "  (0, 161)\t0.13435767267387225\n",
            "  (0, 124)\t0.1261254092591891\n",
            "  (1, 1887)\t0.2648980926621023\n",
            "  (1, 1832)\t0.363095574144571\n",
            "  (1, 938)\t0.13157721405840378\n",
            "  (1, 814)\t0.22252337605745093\n",
            "  (1, 703)\t0.3853171128773299\n",
            "  (1, 662)\t0.2333652273779101\n",
            "  (1, 440)\t0.6057721280739146\n",
            "  (1, 173)\t0.1552892170508488\n",
            "  :\t:\n",
            "  (661, 458)\t0.18377632813194925\n",
            "  (661, 204)\t0.131888045516611\n",
            "  (661, 173)\t0.1329345332267191\n",
            "  (662, 2000)\t0.31888802947883726\n",
            "  (662, 1914)\t0.28063269695860393\n",
            "  (662, 1900)\t0.3880289930042312\n",
            "  (662, 1869)\t0.21037673028825551\n",
            "  (662, 1566)\t0.2464674411156654\n",
            "  (662, 614)\t0.1743743954261097\n",
            "  (662, 503)\t0.3880289930042312\n",
            "  (662, 319)\t0.3656510580272762\n",
            "  (662, 231)\t0.27326299544353133\n",
            "  (662, 204)\t0.15515107780763532\n",
            "  (662, 165)\t0.3880289930042312\n",
            "  (663, 1861)\t0.3479766899316306\n",
            "  (663, 1525)\t0.38841366335257294\n",
            "  (663, 1344)\t0.16907506513660825\n",
            "  (663, 1235)\t0.31661133658636864\n",
            "  (663, 1082)\t0.33969882012611224\n",
            "  (663, 880)\t0.3224714513229742\n",
            "  (663, 772)\t0.2753013002270207\n",
            "  (663, 562)\t0.3014931662638669\n",
            "  (663, 424)\t0.23143532173303305\n",
            "  (663, 288)\t0.3625697220992617\n",
            "  (663, 124)\t0.16771034919341926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape (baris, fitur)\n",
        "print(train_X_tfidf_8020.shape)\n",
        "print(test_X_tfidf_8020.shape)"
      ],
      "metadata": {
        "id": "oF397pxHa2Kt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670acf1c-6417-4568-ca52-e06c0787d545"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(664, 2086)\n",
            "(167, 2086)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection\n",
        "Chi-Square = [10%, 20%, 30%]"
      ],
      "metadata": {
        "id": "1RxbjSRnNwoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "percent_kept = 0.2  # persentase jumlah fitur terbaik yang dipertahankan\n",
        "\n",
        "# jumlah fitur yang dipertahankan\n",
        "num_features = int(percent_kept * train_X_tfidf_8020.shape[1])\n",
        "\n",
        "# objek selector\n",
        "selector = SelectKBest(chi2, k=num_features)\n",
        "\n",
        "# memilih fitur terbaik dari train & test berdasarkan skor chi-square.\n",
        "train_X_tfidf_8020_selected = selector.fit_transform(train_X_tfidf_8020, train_Y)\n",
        "test_X_tfidf_8020_selected = selector.transform(test_X_tfidf_8020)"
      ],
      "metadata": {
        "id": "qCU7T6coN6HJ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_X_tfidf_8020_selected.shape)\n",
        "print(test_X_tfidf_8020_selected.shape)"
      ],
      "metadata": {
        "id": "qZ5uUVGFikoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proses Pelatihan\n",
        "Chi-square = 0.1, 0.2, atau 0.3\n",
        "\n",
        "C= 0.1, 1, 10, atau 100\n",
        "\n",
        "kernel: rbf atau polynomial\n",
        "\n",
        "nilai gamma = 0.0001, 0.001, 0.1, atau 1"
      ],
      "metadata": {
        "id": "U1I___d8fxH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mengimpor kelas SVC dari modul svm dalam library scikit-learn\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# objek model dengan parameternya\n",
        "model = SVC(C=1, kernel='rbf', gamma=\"scale\")\n",
        "\n",
        "# fit --> train/melatih\n",
        "model.fit(train_X_tfidf_8020_selected, train_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "q72hoLtmb6-1",
        "outputId": "9b61630e-c7ce-4af4-afda-a29652b435df"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proses Pengujian"
      ],
      "metadata": {
        "id": "zhR_TMuqfmok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Menggunakan model SVM yang telah dilatih sebelumnya, predict() --> prediksi pada data uji test_X_tfidf_8020.\n",
        "predictions_SVM_8020 = model.predict(test_X_tfidf_8020_selected)\n",
        "\n",
        "# Data frame untuk menampilkan hasil\n",
        "test_prediction_8020 = pd.DataFrame()\n",
        "test_prediction_8020['Reviews'] = test_X\n",
        "test_prediction_8020['Label'] = predictions_SVM_8020\n",
        "\n",
        "# Menghitung akurasi prediksi membandingkan hasil prediksi predictions_SVM_8020 dengan label sebenarnya test_Y menggunakan fungsi accuracy_score.\n",
        "SVM_accuracy_8020 = accuracy_score(predictions_SVM_8020, test_Y)*100\n",
        "# Membulatkan nilai akurasi menjadi 1 angka desimal menggunakan fungsi round.\n",
        "SVM_accuracy_8020 = round(SVM_accuracy_8020,1)"
      ],
      "metadata": {
        "id": "blLsegBdcFLG"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan hasil test\n",
        "test_prediction_8020"
      ],
      "metadata": {
        "id": "VCUESoSmccOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "80f48f91-5f94-45ef-ac7c-83ba583a5387"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Reviews  Label\n",
              "610  kecewa sih sen nya warna hitam pas dateng nya ...      0\n",
              "818  produk bagus sesuai sama gambar banget gitu ha...      1\n",
              "290   bagus cuman susah atur jam nya susah tekan tekan      0\n",
              "559     warna beda jauh digmbr jatuh nya wrnanya gelap      0\n",
              "168  bagus kacamata mewah kayak mahal banget tebel ...      1\n",
              "..                                                 ...    ...\n",
              "192                        bagus cuma kirim lama bagus      1\n",
              "650  kecewa ukur kaya ukur kecil bgt bahan tipis st...      0\n",
              "456  jual gak amanah pesan datang cuma responnya la...      0\n",
              "773                                              bagus      1\n",
              "531  kecewa sen sma cepol tpi dateng kerudung nya d...      0\n",
              "\n",
              "[167 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c074b30-f33d-4953-9187-80e82d3700f8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>kecewa sih sen nya warna hitam pas dateng nya ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>818</th>\n",
              "      <td>produk bagus sesuai sama gambar banget gitu ha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>bagus cuman susah atur jam nya susah tekan tekan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>warna beda jauh digmbr jatuh nya wrnanya gelap</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>bagus kacamata mewah kayak mahal banget tebel ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>bagus cuma kirim lama bagus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>kecewa ukur kaya ukur kecil bgt bahan tipis st...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>jual gak amanah pesan datang cuma responnya la...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>bagus</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>kecewa sen sma cepol tpi dateng kerudung nya d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>167 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c074b30-f33d-4953-9187-80e82d3700f8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c074b30-f33d-4953-9187-80e82d3700f8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c074b30-f33d-4953-9187-80e82d3700f8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test_prediction_8020.to_csv(\"test_prediction_8020.csv\")"
      ],
      "metadata": {
        "id": "KEO1XouCdSC1"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan akurasi\n",
        "SVM_accuracy_8020"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOgYZcT8c7IF",
        "outputId": "29e2c9df-3b33-4d94-8705-eb6a7f68f01d"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.8"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy, Precision, Recall, f1-score"
      ],
      "metadata": {
        "id": "tBBxpU6Jf-e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print (\"\\nHere is the classification report:\")\n",
        "print (classification_report(test_Y, predictions_SVM_8020, zero_division='warn'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqSJ3pS-dBlt",
        "outputId": "87742c01-6bfd-4a96-c0f9-d2438cec75c5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.93        84\n",
            "           1       1.00      0.86      0.92        83\n",
            "\n",
            "    accuracy                           0.93       167\n",
            "   macro avg       0.94      0.93      0.93       167\n",
            "weighted avg       0.94      0.93      0.93       167\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the SVM classifier"
      ],
      "metadata": {
        "id": "urr1YhwVgCV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = \"barangnya bagus banget\"\n",
        "review_vector = tfidf_vect_8020.transform([review]) # vectorizing\n",
        "#print(model.predict(review_vector))\n",
        "\n",
        "if(model.predict(review_vector)==1):\n",
        "  print(\"Positif\")\n",
        "else:\n",
        "  print(\"Negatif\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dha1tBsBeYXO",
        "outputId": "51fe985e-0b32-44e9-ee17-26581c6a4ae6"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the trained model and vectorizer"
      ],
      "metadata": {
        "id": "X-JctY2GDyGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "#menyimpan model svm\n",
        "joblib.dump(model, \"model.pkl\")\n",
        "#menyimpan objek TfidfVectorizer\n",
        "joblib.dump(tfidf_vect_8020, \"vectorizer.pkl\")"
      ],
      "metadata": {
        "id": "dGnTBAyCD9Xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc913b8-f8b7-40d1-b9a0-33324645e789"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mencari Parameter Terbaik\n",
        "Iterasi proses feature selection sampai evaluasi untuk mencari kombinasi parameter terbaik"
      ],
      "metadata": {
        "id": "oLzcdl6UJSJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "chi = [0.1, 0.2, 0.3]\n",
        "c = [0.1, 1, 10, 100]\n",
        "kernel = ['rbf', 'poly']\n",
        "gamma = [0.0001, 0.001, 0.1, 1, 'scale', 'auto']\n",
        "\n",
        "def mulai(h, i, j, k):\n",
        "    percent_kept = h\n",
        "    num_features = int(percent_kept * train_X_tfidf_8020.shape[1])\n",
        "    selector = SelectKBest(chi2, k=num_features)\n",
        "    train_X_tfidf_8020_selected = selector.fit_transform(train_X_tfidf_8020, train_Y)\n",
        "    test_X_tfidf_8020_selected = selector.transform(test_X_tfidf_8020)\n",
        "\n",
        "    print(f\"Chi Square = {h}\\tParameter: c={i}, kernel={j}, gamma={k}\")\n",
        "    model = SVC(C=i, kernel=j, gamma=k)\n",
        "    model.fit(train_X_tfidf_8020_selected, train_Y)\n",
        "\n",
        "    predictions_SVM_8020 = model.predict(test_X_tfidf_8020_selected)\n",
        "    test_prediction_8020 = pd.DataFrame()\n",
        "    test_prediction_8020['Reviews'] = test_X\n",
        "    test_prediction_8020['Label'] = predictions_SVM_8020\n",
        "    SVM_accuracy_8020 = accuracy_score(predictions_SVM_8020, test_Y) * 100\n",
        "    SVM_accuracy_8020 = round(SVM_accuracy_8020, 1)\n",
        "\n",
        "    print(f\"Akurasi: {SVM_accuracy_8020}\")\n",
        "    print(\"Here is the classification report:\")\n",
        "    print(classification_report(test_Y, predictions_SVM_8020, zero_division=0.0), end=\"\\n\")\n",
        "    print(\"============================================================\")\n",
        "\n",
        "    data.append({'Chi Square': h, 'C': i, 'Kernel': j, 'Gamma': k, 'Accuracy': SVM_accuracy_8020})\n",
        "\n",
        "for h in chi:\n",
        "  data = []\n",
        "  print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
        "  print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
        "  for i in c:\n",
        "    for j in kernel:\n",
        "      for k in gamma:\n",
        "        mulai(h, i, j, k)\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  # Sort the DataFrame by Accuracy in descending order\n",
        "  df_sorted = df.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "  # Count the number of combinations with the same accuracy\n",
        "  accuracy_counts = df_sorted['Accuracy'].value_counts().reset_index()\n",
        "  accuracy_counts.columns = ['Accuracy', 'Count']\n",
        "  accuracy_counts_sorted = accuracy_counts.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "  print(\"All Combinations:\")\n",
        "  print(df)\n",
        "  print(\"\\nWorst Combination:\")\n",
        "  print(df_sorted.tail(1))\n",
        "  print(\"\\nModerate Combination:\")\n",
        "  print(df_sorted.iloc[len(df_sorted) // 2])\n",
        "  print(\"\\nBest Combination:\")\n",
        "  print(df_sorted.head(1))\n",
        "  print(\"\\nAccuracy Counts:\")\n",
        "  print(accuracy_counts_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9ykwesBFOSF",
        "outputId": "b7cbd890-bb16-4c16-f298-a49475c4c17e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=rbf, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=rbf, gamma=1\n",
            "Akurasi: 72.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.99      0.78        84\n",
            "           1       0.97      0.46      0.62        83\n",
            "\n",
            "    accuracy                           0.72       167\n",
            "   macro avg       0.81      0.72      0.70       167\n",
            "weighted avg       0.81      0.72      0.70       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=rbf, gamma=scale\n",
            "Akurasi: 74.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.99      0.79        84\n",
            "           1       0.98      0.49      0.66        83\n",
            "\n",
            "    accuracy                           0.74       167\n",
            "   macro avg       0.82      0.74      0.73       167\n",
            "weighted avg       0.82      0.74      0.73       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=poly, gamma=1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=poly, gamma=scale\n",
            "Akurasi: 52.7\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.68        84\n",
            "           1       1.00      0.05      0.09        83\n",
            "\n",
            "    accuracy                           0.53       167\n",
            "   macro avg       0.76      0.52      0.39       167\n",
            "weighted avg       0.76      0.53      0.39       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=0.1, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=rbf, gamma=0.1\n",
            "Akurasi: 80.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      1.00      0.84        84\n",
            "           1       1.00      0.61      0.76        83\n",
            "\n",
            "    accuracy                           0.81       167\n",
            "   macro avg       0.86      0.81      0.80       167\n",
            "weighted avg       0.86      0.81      0.80       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=rbf, gamma=1\n",
            "Akurasi: 89.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91        84\n",
            "           1       0.97      0.82      0.89        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=rbf, gamma=scale\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91        84\n",
            "           1       0.97      0.83      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=poly, gamma=1\n",
            "Akurasi: 51.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67        84\n",
            "           1       1.00      0.02      0.05        83\n",
            "\n",
            "    accuracy                           0.51       167\n",
            "   macro avg       0.75      0.51      0.36       167\n",
            "weighted avg       0.75      0.51      0.36       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=poly, gamma=scale\n",
            "Akurasi: 67.7\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.99      0.75        84\n",
            "           1       0.97      0.36      0.53        83\n",
            "\n",
            "    accuracy                           0.68       167\n",
            "   macro avg       0.79      0.67      0.64       167\n",
            "weighted avg       0.79      0.68      0.64       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=1, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=rbf, gamma=0.1\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.98      0.91        84\n",
            "           1       0.97      0.83      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=rbf, gamma=1\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91        84\n",
            "           1       0.96      0.84      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=rbf, gamma=scale\n",
            "Akurasi: 89.2\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90        84\n",
            "           1       0.95      0.83      0.88        83\n",
            "\n",
            "    accuracy                           0.89       167\n",
            "   macro avg       0.90      0.89      0.89       167\n",
            "weighted avg       0.90      0.89      0.89       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=rbf, gamma=auto\n",
            "Akurasi: 66.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      1.00      0.75        84\n",
            "           1       1.00      0.33      0.49        83\n",
            "\n",
            "    accuracy                           0.66       167\n",
            "   macro avg       0.80      0.66      0.62       167\n",
            "weighted avg       0.80      0.66      0.62       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=poly, gamma=1\n",
            "Akurasi: 64.1\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.99      0.73        84\n",
            "           1       0.96      0.29      0.44        83\n",
            "\n",
            "    accuracy                           0.64       167\n",
            "   macro avg       0.77      0.64      0.59       167\n",
            "weighted avg       0.77      0.64      0.59       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=poly, gamma=scale\n",
            "Akurasi: 78.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      1.00      0.82        84\n",
            "           1       1.00      0.57      0.72        83\n",
            "\n",
            "    accuracy                           0.78       167\n",
            "   macro avg       0.85      0.78      0.77       167\n",
            "weighted avg       0.85      0.78      0.77       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=10, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=rbf, gamma=0.001\n",
            "Akurasi: 83.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.99      0.86        84\n",
            "           1       0.98      0.69      0.81        83\n",
            "\n",
            "    accuracy                           0.84       167\n",
            "   macro avg       0.87      0.84      0.83       167\n",
            "weighted avg       0.87      0.84      0.83       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=rbf, gamma=0.1\n",
            "Akurasi: 89.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90        84\n",
            "           1       0.95      0.84      0.89        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.90      0.90      0.90       167\n",
            "weighted avg       0.90      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=rbf, gamma=1\n",
            "Akurasi: 88.0\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.93      0.89        84\n",
            "           1       0.92      0.83      0.87        83\n",
            "\n",
            "    accuracy                           0.88       167\n",
            "   macro avg       0.88      0.88      0.88       167\n",
            "weighted avg       0.88      0.88      0.88       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=rbf, gamma=scale\n",
            "Akurasi: 87.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.93      0.88        84\n",
            "           1       0.92      0.82      0.87        83\n",
            "\n",
            "    accuracy                           0.87       167\n",
            "   macro avg       0.88      0.87      0.87       167\n",
            "weighted avg       0.88      0.87      0.87       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=rbf, gamma=auto\n",
            "Akurasi: 89.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91        84\n",
            "           1       0.99      0.81      0.89        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=poly, gamma=1\n",
            "Akurasi: 76.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      1.00      0.81        84\n",
            "           1       1.00      0.53      0.69        83\n",
            "\n",
            "    accuracy                           0.77       167\n",
            "   macro avg       0.84      0.77      0.75       167\n",
            "weighted avg       0.84      0.77      0.75       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=poly, gamma=scale\n",
            "Akurasi: 79.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.98      0.83        84\n",
            "           1       0.96      0.61      0.75        83\n",
            "\n",
            "    accuracy                           0.80       167\n",
            "   macro avg       0.84      0.80      0.79       167\n",
            "weighted avg       0.84      0.80      0.79       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.1\tParameter: c=100, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "All Combinations:\n",
            "    Chi Square      C Kernel   Gamma  Accuracy\n",
            "0          0.1    0.1    rbf  0.0001      50.3\n",
            "1          0.1    0.1    rbf   0.001      50.3\n",
            "2          0.1    0.1    rbf     0.1      50.3\n",
            "3          0.1    0.1    rbf       1      72.5\n",
            "4          0.1    0.1    rbf   scale      74.3\n",
            "5          0.1    0.1    rbf    auto      50.3\n",
            "6          0.1    0.1   poly  0.0001      50.3\n",
            "7          0.1    0.1   poly   0.001      50.3\n",
            "8          0.1    0.1   poly     0.1      50.3\n",
            "9          0.1    0.1   poly       1      50.3\n",
            "10         0.1    0.1   poly   scale      52.7\n",
            "11         0.1    0.1   poly    auto      50.3\n",
            "12         0.1    1.0    rbf  0.0001      50.3\n",
            "13         0.1    1.0    rbf   0.001      50.3\n",
            "14         0.1    1.0    rbf     0.1      80.8\n",
            "15         0.1    1.0    rbf       1      89.8\n",
            "16         0.1    1.0    rbf   scale      90.4\n",
            "17         0.1    1.0    rbf    auto      50.3\n",
            "18         0.1    1.0   poly  0.0001      50.3\n",
            "19         0.1    1.0   poly   0.001      50.3\n",
            "20         0.1    1.0   poly     0.1      50.3\n",
            "21         0.1    1.0   poly       1      51.5\n",
            "22         0.1    1.0   poly   scale      67.7\n",
            "23         0.1    1.0   poly    auto      50.3\n",
            "24         0.1   10.0    rbf  0.0001      50.3\n",
            "25         0.1   10.0    rbf   0.001      50.3\n",
            "26         0.1   10.0    rbf     0.1      90.4\n",
            "27         0.1   10.0    rbf       1      90.4\n",
            "28         0.1   10.0    rbf   scale      89.2\n",
            "29         0.1   10.0    rbf    auto      66.5\n",
            "30         0.1   10.0   poly  0.0001      50.3\n",
            "31         0.1   10.0   poly   0.001      50.3\n",
            "32         0.1   10.0   poly     0.1      50.3\n",
            "33         0.1   10.0   poly       1      64.1\n",
            "34         0.1   10.0   poly   scale      78.4\n",
            "35         0.1   10.0   poly    auto      50.3\n",
            "36         0.1  100.0    rbf  0.0001      50.3\n",
            "37         0.1  100.0    rbf   0.001      83.8\n",
            "38         0.1  100.0    rbf     0.1      89.8\n",
            "39         0.1  100.0    rbf       1      88.0\n",
            "40         0.1  100.0    rbf   scale      87.4\n",
            "41         0.1  100.0    rbf    auto      89.8\n",
            "42         0.1  100.0   poly  0.0001      50.3\n",
            "43         0.1  100.0   poly   0.001      50.3\n",
            "44         0.1  100.0   poly     0.1      50.3\n",
            "45         0.1  100.0   poly       1      76.6\n",
            "46         0.1  100.0   poly   scale      79.6\n",
            "47         0.1  100.0   poly    auto      50.3\n",
            "\n",
            "Worst Combination:\n",
            "    Chi Square      C Kernel Gamma  Accuracy\n",
            "47         0.1  100.0   poly  auto      50.3\n",
            "\n",
            "Moderate Combination:\n",
            "Chi Square     0.1\n",
            "C             10.0\n",
            "Kernel        poly\n",
            "Gamma          0.1\n",
            "Accuracy      50.3\n",
            "Name: 32, dtype: object\n",
            "\n",
            "Best Combination:\n",
            "    Chi Square     C Kernel Gamma  Accuracy\n",
            "26         0.1  10.0    rbf   0.1      90.4\n",
            "\n",
            "Accuracy Counts:\n",
            "    Accuracy  Count\n",
            "2       90.4      3\n",
            "1       89.8      3\n",
            "9       89.2      1\n",
            "3       88.0      1\n",
            "4       87.4      1\n",
            "5       83.8      1\n",
            "6       80.8      1\n",
            "7       79.6      1\n",
            "8       78.4      1\n",
            "17      76.6      1\n",
            "10      74.3      1\n",
            "11      72.5      1\n",
            "12      67.7      1\n",
            "13      66.5      1\n",
            "14      64.1      1\n",
            "15      52.7      1\n",
            "16      51.5      1\n",
            "0       50.3     27\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=rbf, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=rbf, gamma=1\n",
            "Akurasi: 64.7\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      1.00      0.74        84\n",
            "           1       1.00      0.29      0.45        83\n",
            "\n",
            "    accuracy                           0.65       167\n",
            "   macro avg       0.79      0.64      0.59       167\n",
            "weighted avg       0.79      0.65      0.60       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=rbf, gamma=scale\n",
            "Akurasi: 57.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      1.00      0.70        84\n",
            "           1       1.00      0.14      0.25        83\n",
            "\n",
            "    accuracy                           0.57       167\n",
            "   macro avg       0.77      0.57      0.48       167\n",
            "weighted avg       0.77      0.57      0.48       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=poly, gamma=1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=poly, gamma=scale\n",
            "Akurasi: 51.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67        84\n",
            "           1       1.00      0.02      0.05        83\n",
            "\n",
            "    accuracy                           0.51       167\n",
            "   macro avg       0.75      0.51      0.36       167\n",
            "weighted avg       0.75      0.51      0.36       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=0.1, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=rbf, gamma=0.1\n",
            "Akurasi: 83.2\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.86        84\n",
            "           1       1.00      0.66      0.80        83\n",
            "\n",
            "    accuracy                           0.83       167\n",
            "   macro avg       0.88      0.83      0.83       167\n",
            "weighted avg       0.87      0.83      0.83       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=rbf, gamma=1\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.99      0.91        84\n",
            "           1       0.99      0.82      0.89        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.92      0.90      0.90       167\n",
            "weighted avg       0.92      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=rbf, gamma=scale\n",
            "Akurasi: 92.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.99      0.93        84\n",
            "           1       0.99      0.87      0.92        83\n",
            "\n",
            "    accuracy                           0.93       167\n",
            "   macro avg       0.93      0.93      0.93       167\n",
            "weighted avg       0.93      0.93      0.93       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=poly, gamma=1\n",
            "Akurasi: 51.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67        84\n",
            "           1       1.00      0.02      0.05        83\n",
            "\n",
            "    accuracy                           0.51       167\n",
            "   macro avg       0.75      0.51      0.36       167\n",
            "weighted avg       0.75      0.51      0.36       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=poly, gamma=scale\n",
            "Akurasi: 62.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      1.00      0.73        84\n",
            "           1       1.00      0.24      0.39        83\n",
            "\n",
            "    accuracy                           0.62       167\n",
            "   macro avg       0.79      0.62      0.56       167\n",
            "weighted avg       0.78      0.62      0.56       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=1, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=rbf, gamma=0.1\n",
            "Akurasi: 91.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92        84\n",
            "           1       0.99      0.84      0.91        83\n",
            "\n",
            "    accuracy                           0.92       167\n",
            "   macro avg       0.93      0.92      0.92       167\n",
            "weighted avg       0.92      0.92      0.92       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=rbf, gamma=1\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91        84\n",
            "           1       0.95      0.86      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=rbf, gamma=scale\n",
            "Akurasi: 91.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.95      0.92        84\n",
            "           1       0.95      0.88      0.91        83\n",
            "\n",
            "    accuracy                           0.92       167\n",
            "   macro avg       0.92      0.92      0.92       167\n",
            "weighted avg       0.92      0.92      0.92       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.9\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67        84\n",
            "           1       1.00      0.01      0.02        83\n",
            "\n",
            "    accuracy                           0.51       167\n",
            "   macro avg       0.75      0.51      0.35       167\n",
            "weighted avg       0.75      0.51      0.35       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=poly, gamma=1\n",
            "Akurasi: 64.7\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      1.00      0.74        84\n",
            "           1       1.00      0.29      0.45        83\n",
            "\n",
            "    accuracy                           0.65       167\n",
            "   macro avg       0.79      0.64      0.59       167\n",
            "weighted avg       0.79      0.65      0.60       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=poly, gamma=scale\n",
            "Akurasi: 74.9\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80        84\n",
            "           1       1.00      0.49      0.66        83\n",
            "\n",
            "    accuracy                           0.75       167\n",
            "   macro avg       0.83      0.75      0.73       167\n",
            "weighted avg       0.83      0.75      0.73       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=10, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=rbf, gamma=0.001\n",
            "Akurasi: 85.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.99      0.87        84\n",
            "           1       0.98      0.72      0.83        83\n",
            "\n",
            "    accuracy                           0.86       167\n",
            "   macro avg       0.88      0.86      0.85       167\n",
            "weighted avg       0.88      0.86      0.85       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=rbf, gamma=0.1\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91        84\n",
            "           1       0.95      0.86      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=rbf, gamma=1\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91        84\n",
            "           1       0.95      0.86      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=rbf, gamma=scale\n",
            "Akurasi: 90.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91        84\n",
            "           1       0.95      0.86      0.90        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.91      0.90      0.90       167\n",
            "weighted avg       0.91      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=rbf, gamma=auto\n",
            "Akurasi: 91.0\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92        84\n",
            "           1       0.99      0.83      0.90        83\n",
            "\n",
            "    accuracy                           0.91       167\n",
            "   macro avg       0.92      0.91      0.91       167\n",
            "weighted avg       0.92      0.91      0.91       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=poly, gamma=1\n",
            "Akurasi: 75.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.99      0.80        84\n",
            "           1       0.98      0.52      0.68        83\n",
            "\n",
            "    accuracy                           0.75       167\n",
            "   macro avg       0.83      0.75      0.74       167\n",
            "weighted avg       0.83      0.75      0.74       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=poly, gamma=scale\n",
            "Akurasi: 79.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.95      0.82        84\n",
            "           1       0.93      0.64      0.76        83\n",
            "\n",
            "    accuracy                           0.80       167\n",
            "   macro avg       0.83      0.80      0.79       167\n",
            "weighted avg       0.83      0.80      0.79       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.2\tParameter: c=100, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "All Combinations:\n",
            "    Chi Square      C Kernel   Gamma  Accuracy\n",
            "0          0.2    0.1    rbf  0.0001      50.3\n",
            "1          0.2    0.1    rbf   0.001      50.3\n",
            "2          0.2    0.1    rbf     0.1      50.3\n",
            "3          0.2    0.1    rbf       1      64.7\n",
            "4          0.2    0.1    rbf   scale      57.5\n",
            "5          0.2    0.1    rbf    auto      50.3\n",
            "6          0.2    0.1   poly  0.0001      50.3\n",
            "7          0.2    0.1   poly   0.001      50.3\n",
            "8          0.2    0.1   poly     0.1      50.3\n",
            "9          0.2    0.1   poly       1      50.3\n",
            "10         0.2    0.1   poly   scale      51.5\n",
            "11         0.2    0.1   poly    auto      50.3\n",
            "12         0.2    1.0    rbf  0.0001      50.3\n",
            "13         0.2    1.0    rbf   0.001      50.3\n",
            "14         0.2    1.0    rbf     0.1      83.2\n",
            "15         0.2    1.0    rbf       1      90.4\n",
            "16         0.2    1.0    rbf   scale      92.8\n",
            "17         0.2    1.0    rbf    auto      50.3\n",
            "18         0.2    1.0   poly  0.0001      50.3\n",
            "19         0.2    1.0   poly   0.001      50.3\n",
            "20         0.2    1.0   poly     0.1      50.3\n",
            "21         0.2    1.0   poly       1      51.5\n",
            "22         0.2    1.0   poly   scale      62.3\n",
            "23         0.2    1.0   poly    auto      50.3\n",
            "24         0.2   10.0    rbf  0.0001      50.3\n",
            "25         0.2   10.0    rbf   0.001      50.3\n",
            "26         0.2   10.0    rbf     0.1      91.6\n",
            "27         0.2   10.0    rbf       1      90.4\n",
            "28         0.2   10.0    rbf   scale      91.6\n",
            "29         0.2   10.0    rbf    auto      50.9\n",
            "30         0.2   10.0   poly  0.0001      50.3\n",
            "31         0.2   10.0   poly   0.001      50.3\n",
            "32         0.2   10.0   poly     0.1      50.3\n",
            "33         0.2   10.0   poly       1      64.7\n",
            "34         0.2   10.0   poly   scale      74.9\n",
            "35         0.2   10.0   poly    auto      50.3\n",
            "36         0.2  100.0    rbf  0.0001      50.3\n",
            "37         0.2  100.0    rbf   0.001      85.6\n",
            "38         0.2  100.0    rbf     0.1      90.4\n",
            "39         0.2  100.0    rbf       1      90.4\n",
            "40         0.2  100.0    rbf   scale      90.4\n",
            "41         0.2  100.0    rbf    auto      91.0\n",
            "42         0.2  100.0   poly  0.0001      50.3\n",
            "43         0.2  100.0   poly   0.001      50.3\n",
            "44         0.2  100.0   poly     0.1      50.3\n",
            "45         0.2  100.0   poly       1      75.4\n",
            "46         0.2  100.0   poly   scale      79.6\n",
            "47         0.2  100.0   poly    auto      50.3\n",
            "\n",
            "Worst Combination:\n",
            "    Chi Square      C Kernel Gamma  Accuracy\n",
            "47         0.2  100.0   poly  auto      50.3\n",
            "\n",
            "Moderate Combination:\n",
            "Chi Square     0.2\n",
            "C             10.0\n",
            "Kernel        poly\n",
            "Gamma          0.1\n",
            "Accuracy      50.3\n",
            "Name: 32, dtype: object\n",
            "\n",
            "Best Combination:\n",
            "    Chi Square    C Kernel  Gamma  Accuracy\n",
            "16         0.2  1.0    rbf  scale      92.8\n",
            "\n",
            "Accuracy Counts:\n",
            "    Accuracy  Count\n",
            "5       92.8      1\n",
            "2       91.6      2\n",
            "6       91.0      1\n",
            "1       90.4      5\n",
            "7       85.6      1\n",
            "8       83.2      1\n",
            "9       79.6      1\n",
            "10      75.4      1\n",
            "11      74.9      1\n",
            "3       64.7      2\n",
            "12      62.3      1\n",
            "13      57.5      1\n",
            "4       51.5      2\n",
            "14      50.9      1\n",
            "0       50.3     27\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=rbf, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=rbf, gamma=1\n",
            "Akurasi: 57.5\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      1.00      0.70        84\n",
            "           1       1.00      0.14      0.25        83\n",
            "\n",
            "    accuracy                           0.57       167\n",
            "   macro avg       0.77      0.57      0.48       167\n",
            "weighted avg       0.77      0.57      0.48       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=rbf, gamma=scale\n",
            "Akurasi: 53.9\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.69        84\n",
            "           1       1.00      0.07      0.13        83\n",
            "\n",
            "    accuracy                           0.54       167\n",
            "   macro avg       0.76      0.54      0.41       167\n",
            "weighted avg       0.76      0.54      0.41       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=poly, gamma=1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=poly, gamma=scale\n",
            "Akurasi: 50.9\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.67        84\n",
            "           1       1.00      0.01      0.02        83\n",
            "\n",
            "    accuracy                           0.51       167\n",
            "   macro avg       0.75      0.51      0.35       167\n",
            "weighted avg       0.75      0.51      0.35       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=0.1, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=rbf, gamma=0.1\n",
            "Akurasi: 83.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      1.00      0.86        84\n",
            "           1       1.00      0.67      0.81        83\n",
            "\n",
            "    accuracy                           0.84       167\n",
            "   macro avg       0.88      0.84      0.83       167\n",
            "weighted avg       0.88      0.84      0.83       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=rbf, gamma=1\n",
            "Akurasi: 88.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.98      0.90        84\n",
            "           1       0.97      0.80      0.87        83\n",
            "\n",
            "    accuracy                           0.89       167\n",
            "   macro avg       0.90      0.89      0.89       167\n",
            "weighted avg       0.90      0.89      0.89       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=rbf, gamma=scale\n",
            "Akurasi: 88.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.99      0.90        84\n",
            "           1       0.98      0.78      0.87        83\n",
            "\n",
            "    accuracy                           0.89       167\n",
            "   macro avg       0.90      0.89      0.88       167\n",
            "weighted avg       0.90      0.89      0.88       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=poly, gamma=1\n",
            "Akurasi: 52.1\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      1.00      0.68        84\n",
            "           1       1.00      0.04      0.07        83\n",
            "\n",
            "    accuracy                           0.52       167\n",
            "   macro avg       0.76      0.52      0.37       167\n",
            "weighted avg       0.75      0.52      0.38       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=poly, gamma=scale\n",
            "Akurasi: 59.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      1.00      0.71        84\n",
            "           1       1.00      0.18      0.31        83\n",
            "\n",
            "    accuracy                           0.59       167\n",
            "   macro avg       0.78      0.59      0.51       167\n",
            "weighted avg       0.77      0.59      0.51       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=1, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=rbf, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=rbf, gamma=0.1\n",
            "Akurasi: 91.0\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.99      0.92        84\n",
            "           1       0.99      0.83      0.90        83\n",
            "\n",
            "    accuracy                           0.91       167\n",
            "   macro avg       0.92      0.91      0.91       167\n",
            "weighted avg       0.92      0.91      0.91       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=rbf, gamma=1\n",
            "Akurasi: 91.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.98      0.92        84\n",
            "           1       0.97      0.86      0.91        83\n",
            "\n",
            "    accuracy                           0.92       167\n",
            "   macro avg       0.92      0.92      0.92       167\n",
            "weighted avg       0.92      0.92      0.92       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=rbf, gamma=scale\n",
            "Akurasi: 91.0\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91        84\n",
            "           1       0.95      0.87      0.91        83\n",
            "\n",
            "    accuracy                           0.91       167\n",
            "   macro avg       0.91      0.91      0.91       167\n",
            "weighted avg       0.91      0.91      0.91       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=rbf, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=poly, gamma=1\n",
            "Akurasi: 61.1\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.72        84\n",
            "           1       1.00      0.22      0.36        83\n",
            "\n",
            "    accuracy                           0.61       167\n",
            "   macro avg       0.78      0.61      0.54       167\n",
            "weighted avg       0.78      0.61      0.54       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=poly, gamma=scale\n",
            "Akurasi: 68.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      1.00      0.76        84\n",
            "           1       1.00      0.36      0.53        83\n",
            "\n",
            "    accuracy                           0.68       167\n",
            "   macro avg       0.81      0.68      0.65       167\n",
            "weighted avg       0.81      0.68      0.65       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=10, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=rbf, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=rbf, gamma=0.001\n",
            "Akurasi: 86.2\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.99      0.88        84\n",
            "           1       0.98      0.73      0.84        83\n",
            "\n",
            "    accuracy                           0.86       167\n",
            "   macro avg       0.89      0.86      0.86       167\n",
            "weighted avg       0.89      0.86      0.86       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=rbf, gamma=0.1\n",
            "Akurasi: 89.2\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.95      0.90        84\n",
            "           1       0.95      0.83      0.88        83\n",
            "\n",
            "    accuracy                           0.89       167\n",
            "   macro avg       0.90      0.89      0.89       167\n",
            "weighted avg       0.90      0.89      0.89       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=rbf, gamma=1\n",
            "Akurasi: 89.8\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90        84\n",
            "           1       0.93      0.86      0.89        83\n",
            "\n",
            "    accuracy                           0.90       167\n",
            "   macro avg       0.90      0.90      0.90       167\n",
            "weighted avg       0.90      0.90      0.90       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=rbf, gamma=scale\n",
            "Akurasi: 87.4\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.94      0.88        84\n",
            "           1       0.93      0.81      0.86        83\n",
            "\n",
            "    accuracy                           0.87       167\n",
            "   macro avg       0.88      0.87      0.87       167\n",
            "weighted avg       0.88      0.87      0.87       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=rbf, gamma=auto\n",
            "Akurasi: 88.6\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.99      0.90        84\n",
            "           1       0.98      0.78      0.87        83\n",
            "\n",
            "    accuracy                           0.89       167\n",
            "   macro avg       0.90      0.89      0.88       167\n",
            "weighted avg       0.90      0.89      0.88       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=poly, gamma=0.0001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=poly, gamma=0.001\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=poly, gamma=0.1\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=poly, gamma=1\n",
            "Akurasi: 70.7\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      1.00      0.77        84\n",
            "           1       1.00      0.41      0.58        83\n",
            "\n",
            "    accuracy                           0.71       167\n",
            "   macro avg       0.82      0.70      0.68       167\n",
            "weighted avg       0.81      0.71      0.68       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=poly, gamma=scale\n",
            "Akurasi: 74.9\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.99      0.80        84\n",
            "           1       0.98      0.51      0.67        83\n",
            "\n",
            "    accuracy                           0.75       167\n",
            "   macro avg       0.82      0.75      0.73       167\n",
            "weighted avg       0.82      0.75      0.73       167\n",
            "\n",
            "============================================================\n",
            "Chi Square = 0.3\tParameter: c=100, kernel=poly, gamma=auto\n",
            "Akurasi: 50.3\n",
            "Here is the classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67        84\n",
            "           1       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.50       167\n",
            "   macro avg       0.25      0.50      0.33       167\n",
            "weighted avg       0.25      0.50      0.34       167\n",
            "\n",
            "============================================================\n",
            "All Combinations:\n",
            "    Chi Square      C Kernel   Gamma  Accuracy\n",
            "0          0.3    0.1    rbf  0.0001      50.3\n",
            "1          0.3    0.1    rbf   0.001      50.3\n",
            "2          0.3    0.1    rbf     0.1      50.3\n",
            "3          0.3    0.1    rbf       1      57.5\n",
            "4          0.3    0.1    rbf   scale      53.9\n",
            "5          0.3    0.1    rbf    auto      50.3\n",
            "6          0.3    0.1   poly  0.0001      50.3\n",
            "7          0.3    0.1   poly   0.001      50.3\n",
            "8          0.3    0.1   poly     0.1      50.3\n",
            "9          0.3    0.1   poly       1      50.3\n",
            "10         0.3    0.1   poly   scale      50.9\n",
            "11         0.3    0.1   poly    auto      50.3\n",
            "12         0.3    1.0    rbf  0.0001      50.3\n",
            "13         0.3    1.0    rbf   0.001      50.3\n",
            "14         0.3    1.0    rbf     0.1      83.8\n",
            "15         0.3    1.0    rbf       1      88.6\n",
            "16         0.3    1.0    rbf   scale      88.6\n",
            "17         0.3    1.0    rbf    auto      50.3\n",
            "18         0.3    1.0   poly  0.0001      50.3\n",
            "19         0.3    1.0   poly   0.001      50.3\n",
            "20         0.3    1.0   poly     0.1      50.3\n",
            "21         0.3    1.0   poly       1      52.1\n",
            "22         0.3    1.0   poly   scale      59.3\n",
            "23         0.3    1.0   poly    auto      50.3\n",
            "24         0.3   10.0    rbf  0.0001      50.3\n",
            "25         0.3   10.0    rbf   0.001      50.3\n",
            "26         0.3   10.0    rbf     0.1      91.0\n",
            "27         0.3   10.0    rbf       1      91.6\n",
            "28         0.3   10.0    rbf   scale      91.0\n",
            "29         0.3   10.0    rbf    auto      50.3\n",
            "30         0.3   10.0   poly  0.0001      50.3\n",
            "31         0.3   10.0   poly   0.001      50.3\n",
            "32         0.3   10.0   poly     0.1      50.3\n",
            "33         0.3   10.0   poly       1      61.1\n",
            "34         0.3   10.0   poly   scale      68.3\n",
            "35         0.3   10.0   poly    auto      50.3\n",
            "36         0.3  100.0    rbf  0.0001      50.3\n",
            "37         0.3  100.0    rbf   0.001      86.2\n",
            "38         0.3  100.0    rbf     0.1      89.2\n",
            "39         0.3  100.0    rbf       1      89.8\n",
            "40         0.3  100.0    rbf   scale      87.4\n",
            "41         0.3  100.0    rbf    auto      88.6\n",
            "42         0.3  100.0   poly  0.0001      50.3\n",
            "43         0.3  100.0   poly   0.001      50.3\n",
            "44         0.3  100.0   poly     0.1      50.3\n",
            "45         0.3  100.0   poly       1      70.7\n",
            "46         0.3  100.0   poly   scale      74.9\n",
            "47         0.3  100.0   poly    auto      50.3\n",
            "\n",
            "Worst Combination:\n",
            "    Chi Square      C Kernel Gamma  Accuracy\n",
            "47         0.3  100.0   poly  auto      50.3\n",
            "\n",
            "Moderate Combination:\n",
            "Chi Square     0.3\n",
            "C             10.0\n",
            "Kernel        poly\n",
            "Gamma          0.1\n",
            "Accuracy      50.3\n",
            "Name: 32, dtype: object\n",
            "\n",
            "Best Combination:\n",
            "    Chi Square     C Kernel Gamma  Accuracy\n",
            "27         0.3  10.0    rbf     1      91.6\n",
            "\n",
            "Accuracy Counts:\n",
            "    Accuracy  Count\n",
            "10      91.6      1\n",
            "2       91.0      2\n",
            "16      89.8      1\n",
            "15      89.2      1\n",
            "1       88.6      3\n",
            "14      87.4      1\n",
            "13      86.2      1\n",
            "12      83.8      1\n",
            "11      74.9      1\n",
            "17      70.7      1\n",
            "3       68.3      1\n",
            "9       61.1      1\n",
            "8       59.3      1\n",
            "7       57.5      1\n",
            "6       53.9      1\n",
            "5       52.1      1\n",
            "4       50.9      1\n",
            "0       50.3     28\n"
          ]
        }
      ]
    }
  ]
}